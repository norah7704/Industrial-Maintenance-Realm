

# 1 Business Understanding
Determine the tyoe of faiure to reduce machine downtime and ensure the reliability of correct maintenance
# 2 Data Understanding
2.1 Import the libraries used in the project
# Data wrangling
import pandas as pd
import numpy as np

# Data visualization
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# Off FutureWarnings
import warnings
warnings.filterwarnings('ignore')

#Resampling
from imblearn.over_sampling import SMOTENC
from sklearn.utils import class_weight

#Dimension Reduction
from sklearn.decomposition import PCA

# Preprocessing
from sklearn.preprocessing import StandardScaler, PowerTransformer, OrdinalEncoder, OneHotEncoder
from sklearn.preprocessing import LabelEncoder

# Models
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV

# Models Pipelines
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline as ImbPipeline

# Model evaluation
from sklearn import metrics
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, f1_score
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import confusion_matrix

# Save model
import pickle
2.2 Upload Dataframe as df
df=pd.read_csv("/content/failures_data.csv")
df.head(5)
2.3 Check if duplicate value exist
# Verify if the data has duplicate values
data_duplicates = df.duplicated().sum()
print("Total duplicated values: ", data_duplicates)
2.4 Check if any missing value exists
# Verify if the data has missing values
data_null = df.isnull().sum().sum()
print("Total missing values: ", data_null)
2.5 Verify the data structure
## Verify the data structure
df.info()
2.6 Describe the numeric features
## Numeric features analysis
df.describe()
## Numeric features analysis
df.describe(include='all').T
2.7 Verify "Target" Column Distribution
## Verify the proportion of column "Target"
df.Target.value_counts()
2.8 Verify "Failure Type" distribution
# Verify the proportion of column "Failure_Type"
df['Failure Type'].value_counts()
# 3. Data Preparation
3.1 Rename the columns
rename_columns = {
    'UDI':'ID',
    'Air temperature [K]': 'Air_temperature',
    'Process temperature [K]': 'Process_temperature',
    'Rotational speed [rpm]': 'Rotational_speed',
    'Torque [Nm]': 'Torque',
    'Tool wear [min]':'Tool_wear',
    'Product ID': 'Product_ID',
    'Failure Type': 'Failure_type'
}
df.rename(rename_columns, axis=1, inplace=True)
df.head(5)
3.2 Identify redundance rows
# analysing redundance value, count failures on "Target" column
count_failures=(df['Target']==1).sum()
print('Number of failures:', count_failures)

# Sum of occurance of 'Failure_type'other than 'No Failure'
sum_failures=df.loc[(df['Failure_type'] !='No Failure') & (df['Target']==1), 'Failure_type'].count()
print('Sum of failures different of "No Failure":', sum_failures)  # Result analysis will show that there are 9 ambiguos values to be removed
3.3 Remove redundance rows
# FIlter the rows which has 1 in the column "Target" and 'No Failure' in the column 'Failure_type'
rows_to_remove = df[(df['Target']==1) & (df['Failure_type']=='No Failure')]

# Remove this filtered row in the main df
df.drop(rows_to_remove.index, inplace=True)
3.4 Remove columns unnecessary
# Removing unnnecessary columns
drop_columns = ["ID", "Product_ID", "Target"]
df.drop(drop_columns, axis=1, inplace=True)
df.info()
3.5 Remove "Random Failures"
df=df.loc[df['Failure_type'] != 'Random Failures']
df['Failure_type'].value_counts()
3.6 Rename classes of "Type" column
rename_type={
    'L': 'Low',
    'M': 'Medium',
    'H': 'High'
}
df['Type'].replace(rename_type, inplace=True)
3.7 Plot "Type" distribution
# Count types
tipo_contagm = df['Type'].value_counts()

# Show graphic
plt.figure(figsize=(8,6))
ax = sns.countplot(data=df, x='Type')
plt.title('Proportion of Types')
plt.xlabel('Type')
plt.ylabel('Count')

# Add as percentages as labels
total=len(df['Type'])
for p in ax.patches:
  height=p.get_height()
  percentage=(height/ total)*100
  ax.annotate(f'{percentage:.2f}%', (p.get_x()+p.get_width()/2, height), ha='center', va='bottom')
plt.show()
3.8 Plot "Failure_type" distribution
# Count types
tipo_contagm = df['Failure_type'].value_counts()

# Show graphic
plt.figure(figsize=(15,6))
ax = sns.countplot(data=df, x='Failure_type')
plt.title('Proportion of Failure')
plt.xlabel('Type')
plt.ylabel('Count')

# Add as percentages as labels
total=len(df['Failure_type'])
for p in ax.patches:
  height=p.get_height()
  percentage=(height/ total)*100
  ax.annotate(f'{percentage:.2f}%', (p.get_x()+p.get_width()/2, height), ha='center', va='bottom')
plt.show()
3.9 Plot histogram and boxplot with numeric features
NUMERIC_FEATURES= ['Air_temperature', 'Process_temperature', 'Rotational_speed', 'Torque', 'Tool_wear' ]
CATEGORIC_FEATURES= ['Type']

# Create the figure and axes
fig, axes = plt.subplots(nrows=1, ncols=len(NUMERIC_FEATURES), figsize=(15, 5))

# Plot histograms
for i, feature in enumerate(NUMERIC_FEATURES):
  sns.histplot(data=df, x=feature, ax=axes[i])
  axes[i].set_title(f'Histogram: {feature}')

# Adjust subplot
plt.tight_layout()

#show histogram
plt.show()

# Create the figure and axes
fig, axes = plt.subplots(nrows=1, ncols=len(NUMERIC_FEATURES), figsize=(15, 5))

# Plot boxplot side by side
for i, feature in enumerate(NUMERIC_FEATURES):
  sns.boxplot(data=df, y=feature, ax=axes[i])
  axes[i].set_title(f'Boxplot: {feature}')

# Adjust subplot
plt.tight_layout()

#show histogram
plt.show()
3.10 Plot distribution of Failures
df_failure_type = df.loc[df['Failure_type'] != "No Failure"]

# Verification
proportions=df_failure_type['Failure_type'].value_counts(normalize=True)

# Plot pie chart
plt.figure(figsize=(8,6))
plt.pie(proportions, labels=proportions.index, autopct='%1.1f%%', startangle=90)
plt.axis('equal')
plt.title('Class Distribution')
plt.show()
3.11 Plot numeric correlation with heatmap
df.head(5)
df_heat=df.copy()
drop_columns = ["Type", "Failure_type"]
df_heat.drop(drop_columns, axis=1, inplace=True)
df_heat.head(5)
df.head(5)
# Plot correlation of numeric values applying mask

corr = df_heat.corr()
plt.figure(figsize = (5,5))
mask = np.triu(np.ones_like(corr, dtype=bool))
sns.heatmap(corr, annot = True, mask=mask, cmap = 'coolwarm', fmt = ".2f")
3.12 Scale numeric features and apply OneHotEncoder for CATEGORIC_FEATURE
# create preprocessor ColumnTransformer to do OneHotEncoder for CATEGORIC_FEATURE and StandardScaler for NUMERIC_FEATURE
# Define the pipelines for numeric and categorical transformations
num_pipeline = Pipeline([
    ('num_features', StandardScaler())
])
cat_pipeline = Pipeline([
    ('cat_features', OneHotEncoder())
])

# Create the ColumnTransformer
preprocessor=ColumnTransformer(transformers=[
    ('num_trans', num_pipeline, NUMERIC_FEATURES),
    ('cat_trans', cat_pipeline, CATEGORIC_FEATURES)
])

# Fit and transform the data
df_transformed = preprocessor.fit_transform(df)

# Converting the transformed data back to a dataframe for easier visualization
# the transformed data will have new column names, especially for the one hot encoded categories
encoded_feature_names = preprocessor.named_transformers_['cat_trans'].get_feature_names_out(CATEGORIC_FEATURES)
new_column_names = list(NUMERIC_FEATURES)+list(encoded_feature_names)
df_transformed = pd.DataFrame(df_transformed, columns=new_column_names)
df_transformed.head()
3.13 Principal Component Analysis (PCA)
# Define PCA function
pca = PCA()
pca.fit(df_transformed)  # Assumindo que df_transformed Ã© o seu DataFrame transformado

# PCA variance explained
exp_var = pca.explained_variance_ratio_
cum_exp_var = exp_var.cumsum()

# Number of components
n_pca_components = len(exp_var)

# Create the graphic
plt.figure(figsize=(10, 6))
bars = plt.bar(range(1, n_pca_components + 1), exp_var, align='center',
               label='Individual explained variance')
plt.step(range(1, n_pca_components + 1), cum_exp_var, where='mid',
         label='Cumulative explained variance', color='red')

# Add labels in each bar
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval*100, 2),
             va='bottom', ha='center', fontsize=8)

# Adjust others elements of the graphic
plt.ylabel('Explained variance percentage')
plt.xlabel('Principal component index')
plt.xticks(ticks=list(range(1, n_pca_components + 1)))
plt.title('PCA Explained Variance')
plt.legend(loc='best')
plt.tight_layout()
plt.show()
3.14 Plot explaination of PCA component
# PCA with 7 components to analyse what explain each component
pca7 = PCA(n_components=7)
X_pca7 = pd.DataFrame(data=pca7.fit_transform(df_transformed), columns=['PC1', 'PC2', 'PC3', 'PC4','PC5', 'PC6', 'PC7'])

# Configure of the graphics
fig, axs = plt.subplots(ncols=7, figsize=(18,5))
fig.suptitle('Loadings magnitude')

all_features = NUMERIC_FEATURES + list(encoded_feature_names)  # Use encoded_feature_names do
pca_loadings = pd.DataFrame(data=pca7.components_, columns=all_features)

#Plot the bar graphics
for j in range(7):
    ax = axs[j]
    sns.barplot(ax=ax, x=pca_loadings.columns, y=pca_loadings.values[j])
    ax.tick_params(axis='x', rotation=90)
    ax.title.set_text('PC'+str(j+1))
plt.show()
# Model
4.1 Create a function to get metrics
from sklearn.metrics import f1_score
def get_metrics(y_true, y_pred):
  # calculate the F1 score for each class
  f1_scores_per_class = f1_score(y_true, y_pred, average=None)

  dict_metrics = {
      'Accuracy': accuracy_score(y_true, y_pred),
      'Balanced Accuracy': balanced_accuracy_score(y_true, y_pred),
      'Macro Recall': recall_score(y_true, y_pred, average='macro'),
      'Macro Precision': precision_score(y_true, y_pred, average='macro'),
      'Macro F1': f1_score(y_true, y_pred, average='macro'),
      'F1 Scores per Class': f1_scores_per_class
  }
  return dict_metrics
4.2 Separate dataset in trin and test


(NUMERIC_FEATURES= ['Air_temperature', 'Process_temperature', 'Rotational_speed', 'Torque', 'Tool_wear' ]

CATEGORIC_FEATURES= ['Type'])
df_model = df.copy()
X = df_model[NUMERIC_FEATURES + CATEGORIC_FEATURES]
y = df_model['Failure_type']
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify=y)
4.3 Create model with PCA and class_weight
# Creating pipeline with PCA analysis and balanced class
pip_model_pca = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('pca', PCA(n_components=4)),
    ('model', RandomForestClassifier(random_state=2023))
])

# Fit pipeline with PCA
weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)
pip_model_pca.fit(X_train, y_train, model__sample_weight=weights)

# Generate Predictions using the correctly fitted pipeline
y_pred = pip_model_pca.predict(X_test)

# Evaluate Metrics
metrics = get_metrics(y_test, y_pred)

# View Results
metrics
Note: Itâs important to remember that PCA is just one of many tools for dimensionality reduction and feature extraction. If PCA is not improving or is even worsening our modelâs performance, itâs entirely reasonable to choose not to use it.
4.4 Create model without PCA and with class_weight
# Creating pipeline without PCA analysis and balanced class with parameter by model
pip_model_no_pca = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', GradientBoostingClassifier(random_state=2023))
])

# Fit pipeline with sample weights
weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)
pip_model_no_pca.fit(X_train, y_train, model__sample_weight=weights)

# Step 1: Generate Predictions
y_pred = pip_model_no_pca.predict(X_test)

# Step 2: Evaluate Metrics
metrics = get_metrics(y_test, y_pred)

# Step 3: View Results
metrics
4.5 Create model without PCA and with SMOTE-NC
# Get categorical feature indices for SMOTENC
categorical_features_indices = [i for i, feature in enumerate(NUMERIC_FEATURES + CATEGORIC_FEATURES)
                                if feature in CATEGORIC_FEATURES]

# Creating the new pipeline with SMOTENC using ImbPipeline
pip_model_smotenc = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smotenc', SMOTENC(categorical_features=categorical_features_indices, random_state=42)),
    ('model', GradientBoostingClassifier(random_state=2023))
])

# Fit the pipeline
pip_model_smotenc.fit(X_train, y_train)

# Generate Predictions
y_pred = pip_model_smotenc.predict(X_test)

# Evaluate Metrics
metrics = get_metrics(y_test, y_pred)

# View Results
metrics
4.6 GridSearchCV to find better model
# Creating pipeline without PCA analysis and balanced class with parameter by model
pip_model_no_pca = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', GradientBoostingClassifier(random_state=2023))
])

# Fit pipeline with sample weights
weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)
pip_model_no_pca.fit(X_train, y_train, model__sample_weight=weights)

# Updated parameters for GridSearchCV
params = {
    'model': [
        LogisticRegressionCV(max_iter=500, random_state=2023),
        RandomForestClassifier(random_state=2023),
        GradientBoostingClassifier(random_state=2023),
        DummyClassifier()
    ],
}

# Running GridSearchCV
grid = GridSearchCV(pip_model_no_pca, params, cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)
grid.fit(X_train, y_train)

# Collecting and printing the results
results = pd.DataFrame(grid.cv_results_)
best_model_index = results['mean_test_score'].idxmax()
best_model_params = results.loc[best_model_index, 'params']

# View results
print("Best model:")
print(best_model_params)
4.7 Tunning the model
# New parameters for fine-tuning the RandomForestClassifier
fine_tune_params = {

    'model__n_estimators': [50, 100, 200, 300, 400, 500],
    'model__max_depth': [None, 5, 10, 15, 20]
}

# Running a new GridSearchCV for fine-tuning
fine_tune_grid = GridSearchCV(pip_model_no_pca, fine_tune_params, cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)
fine_tune_grid.fit(X_train, y_train)

# Collecting and printing the fine-tuned results
fine_tuned_results = pd.DataFrame(fine_tune_grid.cv_results_)
fine_tuned_best_index = fine_tuned_results['mean_test_score'].idxmax()
fine_tuned_best_params = fine_tuned_results.loc[fine_tuned_best_index, 'params']

# Print best model parameters
print("Best fine-tuned model parameters:")
print(fine_tuned_best_params)

# Finding the best estimator paramaters
tuned_model = fine_tune_grid.best_estimator_
y_pred = tuned_model.predict(X_test)

# View new perfomance (focus on F1-score)
get_metrics(y_test, y_pred)
# Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(5, 5))  # Larger figure size
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',  # Use 'd' to format numbers as integers
            xticklabels=np.unique(y_test),
            yticklabels=np.unique(y_pred))
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
plt.title('Confusion Matrix with Fine-Tuned RandomForestClassifier')
plt.show()
