

# 1 Business Understanding
Determine the tyoe of faiure to reduce machine downtime and ensure the reliability of correct maintenance
# 2 Data Understanding
2.1 Import the libraries used in the project
# Data wrangling
import pandas as pd
import numpy as np

# Data visualization
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px

# Off FutureWarnings
import warnings
warnings.filterwarnings('ignore')

#Resampling
from imblearn.over_sampling import SMOTENC
from sklearn.utils import class_weight

#Dimension Reduction
from sklearn.decomposition import PCA

# Preprocessing
from sklearn.preprocessing import StandardScaler, PowerTransformer, OrdinalEncoder, OneHotEncoder
from sklearn.preprocessing import LabelEncoder

# Models
from sklearn.dummy import DummyClassifier
from sklearn.linear_model import LogisticRegression, LogisticRegressionCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.model_selection import GridSearchCV

# Models Pipelines
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from imblearn.pipeline import Pipeline as ImbPipeline

# Model evaluation
from sklearn import metrics
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import accuracy_score, balanced_accuracy_score, recall_score, precision_score, f1_score
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import confusion_matrix

# Save model
import pickle
2.2 Upload Dataframe as df
df=pd.read_csv("/content/failures_data.csv")
df.head(5)
2.3 Check if duplicate value exist
# Verify if the data has duplicate values
data_duplicates = df.duplicated().sum()
print("Total duplicated values: ", data_duplicates)
2.4 Check if any missing value exists
# Verify if the data has missing values
data_null = df.isnull().sum().sum()
print("Total missing values: ", data_null)
2.5 Verify the data structure
## Verify the data structure
df.info()
2.6 Describe the numeric features
## Numeric features analysis
df.describe()
## Numeric features analysis
df.describe(include='all').T
2.7 Verify "Target" Column Distribution
## Verify the proportion of column "Target"
df.Target.value_counts()
2.8 Verify "Failure Type" distribution
# Verify the proportion of column "Failure_Type"
df['Failure Type'].value_counts()
# 3. Data Preparation
3.1 Rename the columns
rename_columns = {
    'UDI':'ID',
    'Air temperature [K]': 'Air_temperature',
    'Process temperature [K]': 'Process_temperature',
    'Rotational speed [rpm]': 'Rotational_speed',
    'Torque [Nm]': 'Torque',
    'Tool wear [min]':'Tool_wear',
    'Product ID': 'Product_ID',
    'Failure Type': 'Failure_type'
}
df.rename(rename_columns, axis=1, inplace=True)
df.head(5)
3.2 Identify redundance rows
# analysing redundance value, count failures on "Target" column
count_failures=(df['Target']==1).sum()
print('Number of failures:', count_failures)

# Sum of occurance of 'Failure_type'other than 'No Failure'
sum_failures=df.loc[(df['Failure_type'] !='No Failure') & (df['Target']==1), 'Failure_type'].count()
print('Sum of failures different of "No Failure":', sum_failures)  # Result analysis will show that there are 9 ambiguos values to be removed
3.3 Remove redundance rows
# FIlter the rows which has 1 in the column "Target" and 'No Failure' in the column 'Failure_type'
rows_to_remove = df[(df['Target']==1) & (df['Failure_type']=='No Failure')]

# Remove this filtered row in the main df
df.drop(rows_to_remove.index, inplace=True)
3.4 Remove columns unnecessary
# Removing unnnecessary columns
drop_columns = ["ID", "Product_ID", "Target"]
df.drop(drop_columns, axis=1, inplace=True)
df.info()
3.5 Remove "Random Failures"
df=df.loc[df['Failure_type'] != 'Random Failures']
df['Failure_type'].value_counts()
3.6 Rename classes of "Type" column
rename_type={
    'L': 'Low',
    'M': 'Medium',
    'H': 'High'
}
df['Type'].replace(rename_type, inplace=True)
3.7 Plot "Type" distribution
# Count types
tipo_contagm = df['Type'].value_counts()

# Show graphic
plt.figure(figsize=(8,6))
ax = sns.countplot(data=df, x='Type')
plt.title('Proportion of Types')
plt.xlabel('Type')
plt.ylabel('Count')

# Add as percentages as labels
total=len(df['Type'])
for p in ax.patches:
  height=p.get_height()
  percentage=(height/ total)*100
  ax.annotate(f'{percentage:.2f}%', (p.get_x()+p.get_width()/2, height), ha='center', va='bottom')
plt.show()
3.8 Plot "Failure_type" distribution
# Count types
tipo_contagm = df['Failure_type'].value_counts()

# Show graphic
plt.figure(figsize=(15,6))
ax = sns.countplot(data=df, x='Failure_type')
plt.title('Proportion of Failure')
plt.xlabel('Type')
plt.ylabel('Count')

# Add as percentages as labels
total=len(df['Failure_type'])
for p in ax.patches:
  height=p.get_height()
  percentage=(height/ total)*100
  ax.annotate(f'{percentage:.2f}%', (p.get_x()+p.get_width()/2, height), ha='center', va='bottom')
plt.show()
3.9 Plot histogram and boxplot with numeric features
NUMERIC_FEATURES= ['Air_temperature', 'Process_temperature', 'Rotational_speed', 'Torque', 'Tool_wear' ]
CATEGORIC_FEATURES= ['Type']

# Create the figure and axes
fig, axes = plt.subplots(nrows=1, ncols=len(NUMERIC_FEATURES), figsize=(15, 5))

# Plot histograms
for i, feature in enumerate(NUMERIC_FEATURES):
  sns.histplot(data=df, x=feature, ax=axes[i])
  axes[i].set_title(f'Histogram: {feature}')

# Adjust subplot
plt.tight_layout()

#show histogram
plt.show()

# Create the figure and axes
fig, axes = plt.subplots(nrows=1, ncols=len(NUMERIC_FEATURES), figsize=(15, 5))

# Plot boxplot side by side
for i, feature in enumerate(NUMERIC_FEATURES):
  sns.boxplot(data=df, y=feature, ax=axes[i])
  axes[i].set_title(f'Boxplot: {feature}')

# Adjust subplot
plt.tight_layout()

#show histogram
plt.show()
3.10 Plot distribution of Failures
df_failure_type = df.loc[df['Failure_type'] != "No Failure"]

# Verification
proportions=df_failure_type['Failure_type'].value_counts(normalize=True)

# Plot pie chart
plt.figure(figsize=(8,6))
plt.pie(proportions, labels=proportions.index, autopct='%1.1f%%', startangle=90)
plt.axis('equal')
plt.title('Class Distribution')
plt.show()
3.11 Plot numeric correlation with heatmap
df.head(5)
df_heat=df.copy()
drop_columns = ["Type", "Failure_type"]
df_heat.drop(drop_columns, axis=1, inplace=True)
df_heat.head(5)
df.head(5)
# Plot correlation of numeric values applying mask

corr = df_heat.corr()
plt.figure(figsize = (5,5))
mask = np.triu(np.ones_like(corr, dtype=bool))
sns.heatmap(corr, annot = True, mask=mask, cmap = 'coolwarm', fmt = ".2f")
3.12 Scale numeric features and apply OneHotEncoder for CATEGORIC_FEATURE
# create preprocessor ColumnTransformer to do OneHotEncoder for CATEGORIC_FEATURE and StandardScaler for NUMERIC_FEATURE
# Define the pipelines for numeric and categorical transformations
num_pipeline = Pipeline([
    ('num_features', StandardScaler())
])
cat_pipeline = Pipeline([
    ('cat_features', OneHotEncoder())
])

# Create the ColumnTransformer
preprocessor=ColumnTransformer(transformers=[
    ('num_trans', num_pipeline, NUMERIC_FEATURES),
    ('cat_trans', cat_pipeline, CATEGORIC_FEATURES)
])

# Fit and transform the data
df_transformed = preprocessor.fit_transform(df)

# Converting the transformed data back to a dataframe for easier visualization
# the transformed data will have new column names, especially for the one hot encoded categories
encoded_feature_names = preprocessor.named_transformers_['cat_trans'].get_feature_names_out(CATEGORIC_FEATURES)
new_column_names = list(NUMERIC_FEATURES)+list(encoded_feature_names)
df_transformed = pd.DataFrame(df_transformed, columns=new_column_names)
df_transformed.head()
3.13 Principal Component Analysis (PCA)
# Define PCA function
pca = PCA()
pca.fit(df_transformed)  # Assumindo que df_transformed é o seu DataFrame transformado

# PCA variance explained
exp_var = pca.explained_variance_ratio_
cum_exp_var = exp_var.cumsum()

# Number of components
n_pca_components = len(exp_var)

# Create the graphic
plt.figure(figsize=(10, 6))
bars = plt.bar(range(1, n_pca_components + 1), exp_var, align='center',
               label='Individual explained variance')
plt.step(range(1, n_pca_components + 1), cum_exp_var, where='mid',
         label='Cumulative explained variance', color='red')

# Add labels in each bar
for bar in bars:
    yval = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval*100, 2),
             va='bottom', ha='center', fontsize=8)

# Adjust others elements of the graphic
plt.ylabel('Explained variance percentage')
plt.xlabel('Principal component index')
plt.xticks(ticks=list(range(1, n_pca_components + 1)))
plt.title('PCA Explained Variance')
plt.legend(loc='best')
plt.tight_layout()
plt.show()
3.14 Plot explaination of PCA component
# PCA with 7 components to analyse what explain each component
pca7 = PCA(n_components=7)
X_pca7 = pd.DataFrame(data=pca7.fit_transform(df_transformed), columns=['PC1', 'PC2', 'PC3', 'PC4','PC5', 'PC6', 'PC7'])

# Configure of the graphics
fig, axs = plt.subplots(ncols=7, figsize=(18,5))
fig.suptitle('Loadings magnitude')

all_features = NUMERIC_FEATURES + list(encoded_feature_names)  # Use encoded_feature_names do
pca_loadings = pd.DataFrame(data=pca7.components_, columns=all_features)

#Plot the bar graphics
for j in range(7):
    ax = axs[j]
    sns.barplot(ax=ax, x=pca_loadings.columns, y=pca_loadings.values[j])
    ax.tick_params(axis='x', rotation=90)
    ax.title.set_text('PC'+str(j+1))
plt.show()
# Model
4.1 Create a function to get metrics
from sklearn.metrics import f1_score
def get_metrics(y_true, y_pred):
  # calculate the F1 score for each class
  f1_scores_per_class = f1_score(y_true, y_pred, average=None)

  dict_metrics = {
      'Accuracy': accuracy_score(y_true, y_pred),
      'Balanced Accuracy': balanced_accuracy_score(y_true, y_pred),
      'Macro Recall': recall_score(y_true, y_pred, average='macro'),
      'Macro Precision': precision_score(y_true, y_pred, average='macro'),
      'Macro F1': f1_score(y_true, y_pred, average='macro'),
      'F1 Scores per Class': f1_scores_per_class
  }
  return dict_metrics
4.2 Separate dataset in trin and test


(NUMERIC_FEATURES= ['Air_temperature', 'Process_temperature', 'Rotational_speed', 'Torque', 'Tool_wear' ]

CATEGORIC_FEATURES= ['Type'])
df_model = df.copy()
X = df_model[NUMERIC_FEATURES + CATEGORIC_FEATURES]
y = df_model['Failure_type']
X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2, stratify=y)
4.3 Create model with PCA and class_weight
# Creating pipeline with PCA analysis and balanced class
pip_model_pca = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('pca', PCA(n_components=4)),
    ('model', RandomForestClassifier(random_state=2023))
])

# Fit pipeline with PCA
weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)
pip_model_pca.fit(X_train, y_train, model__sample_weight=weights)

# Generate Predictions using the correctly fitted pipeline
y_pred = pip_model_pca.predict(X_test)

# Evaluate Metrics
metrics = get_metrics(y_test, y_pred)

# View Results
metrics
Note: It’s important to remember that PCA is just one of many tools for dimensionality reduction and feature extraction. If PCA is not improving or is even worsening our model’s performance, it’s entirely reasonable to choose not to use it.
4.4 Create model without PCA and with class_weight
# Creating pipeline without PCA analysis and balanced class with parameter by model
pip_model_no_pca = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', GradientBoostingClassifier(random_state=2023))
])

# Fit pipeline with sample weights
weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)
pip_model_no_pca.fit(X_train, y_train, model__sample_weight=weights)

# Step 1: Generate Predictions
y_pred = pip_model_no_pca.predict(X_test)

# Step 2: Evaluate Metrics
metrics = get_metrics(y_test, y_pred)

# Step 3: View Results
metrics
4.5 Create model without PCA and with SMOTE-NC
# Get categorical feature indices for SMOTENC
categorical_features_indices = [i for i, feature in enumerate(NUMERIC_FEATURES + CATEGORIC_FEATURES)
                                if feature in CATEGORIC_FEATURES]

# Creating the new pipeline with SMOTENC using ImbPipeline
pip_model_smotenc = ImbPipeline(steps=[
    ('preprocessor', preprocessor),
    ('smotenc', SMOTENC(categorical_features=categorical_features_indices, random_state=42)),
    ('model', GradientBoostingClassifier(random_state=2023))
])

# Fit the pipeline
pip_model_smotenc.fit(X_train, y_train)

# Generate Predictions
y_pred = pip_model_smotenc.predict(X_test)

# Evaluate Metrics
metrics = get_metrics(y_test, y_pred)

# View Results
metrics
4.6 GridSearchCV to find better model
# Creating pipeline without PCA analysis and balanced class with parameter by model
pip_model_no_pca = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('model', GradientBoostingClassifier(random_state=2023))
])

# Fit pipeline with sample weights
weights = class_weight.compute_sample_weight(class_weight='balanced', y=y_train)
pip_model_no_pca.fit(X_train, y_train, model__sample_weight=weights)

# Updated parameters for GridSearchCV
params = {
    'model': [
        LogisticRegressionCV(max_iter=500, random_state=2023),
        RandomForestClassifier(random_state=2023),
        GradientBoostingClassifier(random_state=2023),
        DummyClassifier()
    ],
}

# Running GridSearchCV
grid = GridSearchCV(pip_model_no_pca, params, cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)
grid.fit(X_train, y_train)

# Collecting and printing the results
results = pd.DataFrame(grid.cv_results_)
best_model_index = results['mean_test_score'].idxmax()
best_model_params = results.loc[best_model_index, 'params']

# View results
print("Best model:")
print(best_model_params)
4.7 Tunning the model
# New parameters for fine-tuning the RandomForestClassifier
fine_tune_params = {

    'model__n_estimators': [50, 100, 200, 300, 400, 500],
    'model__max_depth': [None, 5, 10, 15, 20]
}

# Running a new GridSearchCV for fine-tuning
fine_tune_grid = GridSearchCV(pip_model_no_pca, fine_tune_params, cv=3, scoring='f1_macro', n_jobs=-1, verbose=1)
fine_tune_grid.fit(X_train, y_train)

# Collecting and printing the fine-tuned results
fine_tuned_results = pd.DataFrame(fine_tune_grid.cv_results_)
fine_tuned_best_index = fine_tuned_results['mean_test_score'].idxmax()
fine_tuned_best_params = fine_tuned_results.loc[fine_tuned_best_index, 'params']

# Print best model parameters
print("Best fine-tuned model parameters:")
print(fine_tuned_best_params)

# Finding the best estimator paramaters
tuned_model = fine_tune_grid.best_estimator_
y_pred = tuned_model.predict(X_test)

# View new perfomance (focus on F1-score)
get_metrics(y_test, y_pred)
# Generate the confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot the confusion matrix
plt.figure(figsize=(5, 5))  # Larger figure size
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',  # Use 'd' to format numbers as integers
            xticklabels=np.unique(y_test),
            yticklabels=np.unique(y_pred))
plt.ylabel('Actual label')
plt.xlabel('Predicted label')
plt.title('Confusion Matrix with Fine-Tuned RandomForestClassifier')
plt.show()
